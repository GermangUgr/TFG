
\newmintedfile[MakeConst]{python}{
	%linenos,
	firstline=1,
	lastline=2,
	numbersep=5pt,
	gobble=0,
	frame=lines,
	framesep=2mm,
	tabsize=3,
}

\newmintedfile[LCVQE]{python}{
	%linenos,
	firstline=3,
	lastline=4,
	numbersep=5pt,
	gobble=0,
	frame=lines,
	framesep=2mm,
	tabsize=3,
}

\newmintedfile[TVC]{python}{
	%linenos,
	firstline=5,
	lastline=6,
	numbersep=5pt,
	gobble=0,
	frame=lines,
	framesep=2mm,
	tabsize=3,
}

\newmintedfile[CECM]{python}{
	%linenos,
	firstline=8,
	lastline=9,
	numbersep=5pt,
	gobble=0,
	frame=lines,
	framesep=2mm,
	tabsize=3,
}

\newmintedfile[COPK]{python}{
	%linenos,
	firstline=11,
	lastline=12,
	numbersep=5pt,
	gobble=0,
	frame=lines,
	framesep=2mm,
	tabsize=3,
}

\newmintedfile[RDPM]{python}{
	%linenos,
	firstline=14,
	lastline=15,
	numbersep=5pt,
	gobble=0,
	frame=lines,
	framesep=2mm,
	tabsize=3,
}

\chapter{Implementación}\label{ch:Impl}

El objetivo de este capítulo es dar una visión general de los métodos y herramientas empleadas para la implementación de los algoritmos expuestos en el Capítulo \ref{ch:Algoritmos}, así como servir de guía para su utilización. Para ello tomamos como referencia la implementación de estos métodos en Matlab, resultado de un trabajo colaborativo en el que participan varios de los autores citados en este trabajo. \cite{Metodos}

\section{Entorno de desarrollo}

Para la implementación es esencial disponer de un entorno de desarrollo que permita manejar de manera eficiente los múltiples archivos que contendrán el código. De igual forma debemos disponer de herramientas de depuración de fácil uso. Por ello el entorno recomendado es PyCharm, desarrollado por la empresa JetBrains.

PyCharm ofrece multitud de herramientas que hacen el desarrollo de grandes cantidades de código una tarea asequible, ayudándonos a seguir el estándar de programación de Python y poniendo a nuestra disposición un depurador de código completo.

\section{Bibliotecas empleadas en el desarrollo}

Para la implementación de las funcionalidades será necesario hacer uso de algunas bibliotecas de Python que nos permitan realizar cálculos y procedimientos básicos de forma sencilla.

Como no podía ser de otra manera, haremos uso de \texttt{NumPy}, una de las bibliotecas más completas y  extendidas de Python. \texttt{NumPy} nos permite trabajar con matrices de manera eficiente, lo que es esencial para trabajar con grandes cantidades de datos que, a menudo, viene especificados en forma de matriz. \texttt{NumPy} integra operaciones con matrices, como la suma, la resta o la multiplicación y el cálculo de la inversa o del determinante de manera sencilla.

Emplearemos también la biblioteca \texttt{math}, que pone a nuestra disposición multitud de operaciones que no viene definidas en el lenguaje, como pueden ser el cálculo del factorial o el logaritmo.

La biblioteca \texttt{SciPy} es una de las bibliotecas para Python que integra métodos numéricos. \texttt{SciPy} ofrece una API sencilla de usar para el usuario, con funcionalidades como el cálculo de distintas medidas de distancia en un espacio dado, o el de funciones complejas. Un ejemplo de estas últimas pueden ser: el valor absoluto del logaritmo de la función Gamma para entradas reales (\texttt{gammaln}), o el de la derivada logarítmica de la función Gamma (\texttt{digamma}), cálculos necesarios para la implementación de algunos métodos.

Otra de las bibliotecas que podemos encontrar de utilidad para el desarrollo puede ser \texttt{scikit-learn}, una de las más ampliamente usadas por la comunidad para el desarrollo de aplicaciones de aprendizaje automático de cualquier tipo. \texttt{scikit-learn} pone a nuestra disposición métodos clásicos, como \acf{KM}, o \acf{FKM}, que a menudo se emplean como métodos de inicialización en funcionalidades más complejas.

Por último, y aunque no sean estrictamente necesarias para la implementación, emplearemos las bibliotecas \texttt{Matplotlib} y \texttt{time} para obtener representaciones de los resultados obtenidos con los métodos implementados y tomar las mediciones de tiempo respectivamente. \texttt{Matplotlib} permite un alto nivel de personalización en representaciones, haciendo posible incluir toda la información que sea necesaria para su comprensión. 

\section{Funcionalidades desarrolladas}

Uno de los objetivos de este trabajo es poner a disposición de la comunidad algunos de los métodos de clustering con restricciones que existen en la actualidad \cite{MetodosPython}. A continuación se ofrece la documentación de los métodos implementados.

\subsection{Función para generar restricciones} \label{genConst}

La función \texttt{gen\_rand\_const} crea un conjunto de restricciones en base a un conjunto de datos. El método que sigue para ello es simple: basta con seleccionar de forma aleatoria dos instancias y establecer una restricción de tipo \acs{ML} o \acs{CL} en función de si las instancias pertenecen o no a la misma clase. Dado que el método necesita como argumento las etiquetas (un oráculo), puede no ser de utilidad en un caso real en el que no conozcamos la clase a la que pertenece cada objeto; sin embargo es válido para realizar experimentos. A continuación se muestra el prototipo del método:


\MakeConst{code.py}

Los parámetros de la función se detallan a continuación:

\begin{itemize}

	\item \textbf{\texttt{X}} {$\longrightarrow$ matriz de $n \times p$ que contiene el conjunto de datos}
	
	\item \textbf{\texttt{y}} {$\longrightarrow$ lista de de etiquetas de longitud $n$ etiquetas asociadas al conjunto de datos.}
	
	\item \textbf{\texttt{mat\_const}} {$\longrightarrow$ matriz de $n \times n$ de restricciones sobre las que se añadirán las nuevas.}
	
	\item \textbf{\texttt{nb\_const}} {$\longrightarrow$ número de restricciones a añadir.}
	
	\item \textbf{\texttt{noise}} {$\longrightarrow$ porcentaje de ruido a introducir en las restricciones.}
	
	\item \textbf{\texttt{prop}} {$\longrightarrow$ booleano que indica si las restricciones deben propagarse, es decir, si la matriz será simétrica respecto a la diagonal principal}

\end{itemize}

La función devuelve una matriz de $n \times n$ que contiene \texttt{nb\_const} nuevas restricciones. Cada elemento de la matriz indica si existe una restricción entre dos instancias y de qué tipo es, esto es, $0$ indica que no existe restricción, $1$ indica que existe una de tipo \acs{ML}, y $-1$ una de tipo \acs{CL}.

\subsection{Función para aplicar COP-K-Medias}

La función \texttt{COPKM} es la encargada de aplicar el algoritmo COP-k-medias (Sección \ref{copkm}) a un conjunto de datos dado. La implementación de esta función esta basada en el trabajo de Behrouz Babaki \cite{Behrouz:2017}. A continuación se muestra el prototipo de la función y se detallan sus parámetros:

\COPK{code.py}

\begin{itemize}
	
	\item \textbf{\texttt{X}} {$\longrightarrow$ matriz de $n \times p$ que contiene el conjunto de datos}
	
	\item \textbf{\texttt{K}} {$\longrightarrow$ número de clusters de la partición resultado}
	
	\item \textbf{\texttt{constraints}} {$\longrightarrow$ matriz de $n \times n$ que contiene el conjunto de restricciones. Siendo $i$ y $j$ los índices que indican filas y columnas respectivamente, un $1$ en la matriz indica una restricción \acs{ML} entre $i$ y $j$, un $-1$ indica una de tipo \acs{CL}, y un $0$ indica que no existe restricción.}
	
	\item \textbf{\texttt{max\_iter}} {$\longrightarrow$ límite de iteraciones para el algoritmo}
	
	\item \textbf{\texttt{tol}} {$\longrightarrow$ factor multiplicativo para el cálculo del umbral del desplazamiento de los centroides por debajo del cual se detiene el proceso de iteración.}
	
	\item \textbf{\texttt{init}} {$\longrightarrow$ modelo de inicialización de los centroides: \texttt{'rand'} para inicialización aleatoria y \texttt{'kmpp'} para inicialización con K-medias++}
	
\end{itemize}

La función devuelve la lista de longitud $n$ que indica la pertenencia de cada instancia a un cluster dado, es decir, la partición del conjunto de datos $X$, y los centroides $V$ asociados a los clusters.

\subsection{Función para aplicar CEKM}

La función \texttt{CEKM} aplica el algoritmo \acs{CEKM} (Sección \ref{cekm}) a un conjunto de datos dado. A continuación se muestra el prototipo de la función y se detallan sus parámetros:

\CECM{code.py}

\begin{itemize}
	
	\item \textbf{\texttt{X}} {$\longrightarrow$ matriz de $n \times p$ que contiene el conjunto de datos}
	
	\item \textbf{\texttt{K}} {$\longrightarrow$ número de clusters de la partición resultado}
	
	\item \textbf{\texttt{constraints}} {$\longrightarrow$ matriz de $n \times n$ que contiene el conjunto de restricciones. Siendo $i$ y $j$ los índices que indican filas y columnas respectivamente, un $1$ en la matriz indica una restricción \acs{ML} entre $i$ y $j$, un $-1$ indica una de tipo \acs{CL}, y un $0$ indica que no existe restricción.}
	
	\item \textbf{\texttt{max\_iter}} {$\longrightarrow$ límite de iteraciones para el algoritmo}
	
	\item \textbf{\texttt{alpha}} {$\longrightarrow$ exponente que controla la penalización penalización por asignar instancias a conjuntos con alta cardinalidad.}
	
	\item \textbf{\texttt{rho}} {$\longrightarrow$ distancia de todos los objetos al conjunto vacío.}
	
	\item \textbf{\texttt{xi}} {$\longrightarrow$ compromiso entre la función objetivo $J_{CEKM}$ y las restricciones (Ecuación \ref{eqn26})}
	
	\item \textbf{\texttt{stop\_thr}} {$\longrightarrow$ umbral por debajo del cual la diferencia entre las posiciones de los centroides no es significativa. Por tanto si dicha diferencia es menor se detiene el proceso de iteración.}
	
	\item \textbf{\texttt{init}} {$\longrightarrow$ modelo de inicialización de los centroides: \texttt{'rand'} para inicialización aleatoria y \texttt{'fkm'} para inicialización con \acf{FKM}}
	
\end{itemize}

La función devuelve la asignación de instancias a clusters calculada a partir la partición difusa, la partición difusa resultado de aplicar la función $BetP(c)$ (Ecuación \ref{eqn7}) a la partición de creencia, los centroides $V$, la matriz que contiene los valores de la función de masa $M$, y el valor de la función $J_{CEKM}$.

\subsection{Función para aplicar LCVQE}

La función \texttt{LCVQE} es la encargada de aplicar el algoritmo \acs{LCVQE} (Sección \ref{lcvqe}) a un conjunto de datos dado. A continuación se muestra el prototipo de la función y se detallan sus parámetros:

\LCVQE{code.py}

\begin{itemize}
	
	\item \textbf{\texttt{X}} {$\longrightarrow$ matriz de $n \times p$ que contiene el conjunto de datos}
	
	\item \textbf{\texttt{K}} {$\longrightarrow$ número de clusters de la partición resultado}
	
	\item \textbf{\texttt{constraints}} {$\longrightarrow$ matriz de restricciones de $|R| \times 3$, en la que cada fila responde al formato $\{x_1, x_2, r\}$, donde $x_1$ y $x_2$ son las instancias implicadas en la restricción, y $r$ indica el tipo de la misma ($1$ para \acs{ML} y $-1$ para \acs{CL}).}
	
	\item \textbf{\texttt{centroids}} {$\longrightarrow$ centroides iniciales}
	
	\item \textbf{\texttt{max\_iter}} {$\longrightarrow$ límite de iteraciones para el algoritmo}
	
\end{itemize}

La función devuelve la lista de longitud $n$ que indica la pertenencia de cada instancia a un cluster dado, es decir, la partición del conjunto de datos $X$, los centroides $V$ asociados a los clusters, el número de iteraciones realizadas y el valor de la función $LCVQE$.

\subsection{Función para aplicar RDPM}

La función \texttt{RDPM} es la encargada de aplicar el algoritmo \acs{RDPM} (Sección \ref{rdpmYtvc}) a un conjunto de datos dado. A continuación se muestra el prototipo de la función y se detallan sus parámetros:

\RDPM{code.py}

\begin{itemize}
	
	\item \textbf{\texttt{X}} {$\longrightarrow$ matriz de $n \times p$ que contiene el conjunto de datos}
	
	\item \textbf{\texttt{lamb}} {$\longrightarrow$ distancia mínima a la que se considera que una instancia no pertenece a un cluster, medida desde el centroide del mismo.}
	
	\item \textbf{\texttt{constraints}} {$\longrightarrow$ matriz de $n \times n$ que contiene el conjunto de restricciones. Siendo $i$ y $j$ los índices que indican filas y columnas respectivamente, un $1$ en la matriz indica una restricción \acs{ML} entre $i$ y $j$, un $-1$ indica una de tipo \acs{CL}, y un $0$ indica que no existe restricción.}
	
	\item \textbf{\texttt{max\_iter}} {$\longrightarrow$ límite de iteraciones para el algoritmo}
	
	\item \textbf{\texttt{xi\_0}} {$\longrightarrow$ parámetro $\xi_0$ del Algoritmo \ref{alg:rdpm}, controla el compromiso entre el peso del conjunto de datos y el del conjunto de restricciones.}
	
	\item \textbf{\texttt{xi\_rate}} {$\longrightarrow$ parámetro $\xi_{rate}$ del Algoritmo \ref{alg:rdpm}, controla el ratio de incremento de $\xi_0$.}
	
\end{itemize}

La función devuelve la lista de longitud $n$ que indica la pertenencia de cada instancia a un cluster dado, es decir, la partición del conjunto de datos $X$, y el número de clusters presentes en ella.

\subsection{Función para aplicar TVClust}

\TVC{code.py}

\begin{itemize}
	
	\item \textbf{\texttt{X}} {$\longrightarrow$ matriz de $n \times p$ que contiene el conjunto de datos}
	
	\item \textbf{\texttt{K}} {$\longrightarrow$ número de clusters de la partición resultado}
	
	\item \textbf{\texttt{constraints}} {$\longrightarrow$ matriz de $n \times n$ que contiene el conjunto de restricciones. Siendo $i$ y $j$ los índices que indican filas y columnas respectivamente, un $1$ en la matriz indica una restricción \acs{ML} entre $i$ y $j$, un $0$ indica una de tipo \acs{CL}, y un $-1$ indica que no existe restricción.}
	
	\item \textbf{\texttt{max\_iter}} {$\longrightarrow$ límite de iteraciones para el algoritmo}
	
	\item \textbf{\texttt{is\_keep\_l}} {$\longrightarrow$ booleano que indica si se debe o no monitorizar la métrica de convergencia.}
	
	\item \textbf{\texttt{alpha}} {$\longrightarrow$ parámetro $\alpha$ involucrado en el Proceso de Dirichlet (para más detalles consultar Sección \ref{rdpmYtvc}).}
	
	\item \textbf{\texttt{stop\_thr}} {$\longrightarrow$ umbral por debajo del cual la mejora en la función objetivo de \acs{TVClust} no se considera significativa y se detiene el proceso de iteración.}
	
\end{itemize}

La función devuelve la lista de longitud $n$ que indica la pertenencia de cada instancia a un cluster dado, es decir, la partición del conjunto de datos $X$, y el número de clusters presentes en ella.








